{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson 4 - TensorFlow and Convolutional Neural Networks\n",
    "\n",
    "This last lesson introduces the main development framework for Artificial Neural Networks: Google's [TensorFlow](https://www.tensorflow.org) library.\n",
    "TensorFlow provides many optimization algorithms, regularization techniques, high-level abstractions (e.g. *layers*) and also logging and visualization tools collected in the [TensorBoard](https://www.tensorflow.org/programmers_guide/summaries_and_tensorboard) suite.\n",
    "We will take advantage of TensorFlow's API to describe the problem of regularization and the class of Convolutional Neural Networks.\n",
    "\n",
    "### Summary\n",
    "\n",
    "* [TensorFlow](#tensorflow)\n",
    "* [The MNIST dataset](#mnist)\n",
    "* [Building a model in TensorFlow](#tfmodel)\n",
    "* [Overfitting and regularization](#overfitregularize)\n",
    "* [Spatial locality and sparse connectivity](#sparseconnect)\n",
    "* [Layers](#layers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=tensorflow></a>\n",
    "### TensorFlow\n",
    "\n",
    "TensorFlow was initially released in late 2015 to allow Machine Learning researchers to use a production-level framework for designing and testing their models.\n",
    "\n",
    "Discussions about pros and cons with respect to other frameworks are left to dedicated [blog posts](https://deeplearning4j.org/compare-dl4j-tensorflow-pytorch).\n",
    "A main point to use TensorFlow is that although it requires much effort to get confidence with, it pays off many times over due to its flexibility (passing from research models to deployment models is quite straightforward since the syntax is the same) and community support.\n",
    "\n",
    "TensorFlow is based on the *dataflow* programming model which has been studied during the last two lessons.\n",
    "This means that almost every action a programmer wants his program to do has to be thought to as an [**Operation**](https://www.tensorflow.org/api_docs/python/tf/Operation), while data is stored in [**Tensor**](https://www.tensorflow.org/api_docs/python/tf/Tensor) objects.\n",
    "\n",
    "A tricky difference comes in when we talk about [**Variable**](https://www.tensorflow.org/api_docs/python/tf/Variable) objects: these class represents a wrapper of `tf.Operation`, `tf.Tensor` objects, and maintenance functions to allow TensorFlow to initialize, update, load and store parameters into them.\n",
    "After all, what defines an Artificial Neural Network are its architecture and its parameters: maybe TensorFlow's implementation is not the most transparent one but, as already said, it comes with many advantages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=mnist></a>\n",
    "### The MNIST dataset\n",
    "\n",
    "The [MINST database](http://yann.lecun.com/exdb/mnist/) is a set of greyscale images of 28-by-28 pixels representing decimal digits from zero to nine.\n",
    "It is composed by a training set containing 60000 examples and by a test set containing 10000 examples.\n",
    "\n",
    "The problem is a multinomial logistic regression: a model $f_{\\theta}: X \\to Y$ should map images (points of $X$) to one of ten classes ($Y = \\{0, 1, \\dots 9\\}$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "if sys.platform == 'win32':\n",
    "    WORKING_DIRECTORY = '.\\MNIST'\n",
    "elif sys.platform == 'linux':\n",
    "    WORKING_DIRECTORY = './MNIST'\n",
    "    \n",
    "def load_mnist(valid_frac=0.1):\n",
    "    # load MNIST\n",
    "    mnist = input_data.read_data_sets(os.path.join(WORKING_DIRECTORY, 'data'), one_hot=True)\n",
    "    # load training data\n",
    "    training_x = mnist.train.images\n",
    "    training_y_hat = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "    # separate training samples from validation samples\n",
    "    num_train_samples = len(training_x)\n",
    "    num_val_samples = int((1.0-valid_frac) * num_train_samples)\n",
    "    train_x = training_x[:num_val_samples]\n",
    "    train_y_hat = training_y_hat[:num_val_samples]\n",
    "    valid_x = training_x[num_val_samples:]\n",
    "    valid_y_hat = training_y_hat[num_val_samples:]\n",
    "    # load test data\n",
    "    test_x = mnist.test.images\n",
    "    test_y_hat = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "    \n",
    "    return list(zip(train_x, train_y_hat)), list(zip(valid_x, valid_y_hat)), list(zip(test_x, test_y_hat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-fc455d7510c8>:10: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\matte\\Anaconda3\\envs\\deepteaching\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\matte\\Anaconda3\\envs\\deepteaching\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting .\\MNIST\\data\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\matte\\Anaconda3\\envs\\deepteaching\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting .\\MNIST\\data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\matte\\Anaconda3\\envs\\deepteaching\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting .\\MNIST\\data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting .\\MNIST\\data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\matte\\Anaconda3\\envs\\deepteaching\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVoAAAD8CAYAAAA2Y2wxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCIJl/h9NTjTP+x4F7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28113f86f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train, test, valid = load_mnist()\n",
    "\n",
    "# plot first 16 images\n",
    "num_rows = 4\n",
    "num_cols = 4\n",
    "fig1 = plt.figure()\n",
    "for i in range(0, num_rows*num_cols):\n",
    "    img = np.reshape(train[i][0], (28, 28))\n",
    "    fig1.add_subplot(num_rows, num_cols, i+1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=tfmodel></a>\n",
    "### Building a model in TensorFlow\n",
    "\n",
    "TensorFlow programs should leverage Python's object-orientedness.\n",
    "\n",
    "Each `model` class should have at least a private `__build` method (called by `__init__`) and public `train` and `infer` methods:\n",
    "* the `__build` method should take care of assembling the computational graph, and may be decomposed in submethods corresponding to the mathematical transformations your model has been thinked to represent;\n",
    "* to make it easier for other researchers to replicate the model you build and its respective training experiment, training data consumed by the `train` method should be retrieved and loaded by a specific private procedure `__load_data`;\n",
    "* in contrast, it should be possible to pass whichever compatible inputs to the `infer` method, to allow quick tests on user-provided data.\n",
    "\n",
    "This approach allows other researchers and engineers to:\n",
    "* quickly reuse functions that define specific sequences of computational nodes, representing specific mathematical transformations;\n",
    "* easily reproduce your ideas;\n",
    "* quickly move from a research model to a deployment one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MNISTFullyConnected():\n",
    "    def __init__(self, num_hidden):\n",
    "        self.learning_rate = 0.001\n",
    "        self.momentum = 0.8\n",
    "        self.num_epochs = 1\n",
    "        self.num_inputs = 784\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_outputs = 10\n",
    "        self.__build(self.num_hidden)\n",
    "        self.logdir = os.path.join(WORKING_DIRECTORY, 'fully_connected')\n",
    "        self.saver = tf.train.Saver()\n",
    "        \n",
    "    def __load_data(self, valid_frac=0.1):\n",
    "        # load MNIST\n",
    "        mnist = input_data.read_data_sets(os.path.join(WORKING_DIRECTORY, 'data'), one_hot=True)\n",
    "        # load training data\n",
    "        training_x = mnist.train.images\n",
    "        training_y_hat = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "        # separate training samples from validation samples\n",
    "        num_train_samples = len(training_x)\n",
    "        num_val_samples = int((1.0-valid_frac) * num_train_samples)\n",
    "        train_x = training_x[:num_val_samples]\n",
    "        train_y_hat = training_y_hat[:num_val_samples]\n",
    "        valid_x = training_x[num_val_samples:]\n",
    "        valid_y_hat = training_y_hat[num_val_samples:]\n",
    "        # load test data\n",
    "        test_x = mnist.test.images\n",
    "        test_y_hat = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "        return list(zip(train_x, train_y_hat)), list(zip(valid_x, valid_y_hat)), list(zip(test_x, test_y_hat))\n",
    "        \n",
    "    def __build(self, num_hidden):\n",
    "        logits = self.__core(num_hidden)\n",
    "        self.__inference(logits)\n",
    "        self.__training(logits)\n",
    "        self.__testing()\n",
    "        \n",
    "    def __core(self, num_hidden):\n",
    "        with tf.name_scope('input_layer') as scope:\n",
    "            self.X = tf.placeholder(tf.float32, [None, self.num_inputs], name='image')\n",
    "        with tf.name_scope('hidden_layer') as scope:\n",
    "            w_h = tf.Variable(tf.truncated_normal((self.num_inputs, num_hidden)), name='weights')\n",
    "            b_h = tf.Variable(tf.zeros((1, num_hidden)), name='bias')\n",
    "            hidden_scores = tf.add(tf.matmul(self.X, w_h), b_h, name='linear')\n",
    "            hidden_act = tf.sigmoid(hidden_scores, name='activation')\n",
    "        with tf.name_scope('output_layer') as scope:\n",
    "            w_out = tf.Variable(tf.truncated_normal((num_hidden, self.num_outputs)), name='weights')\n",
    "            b_out = tf.Variable(tf.zeros((1, self.num_outputs)), name='bias')\n",
    "            logits = tf.add(tf.matmul(hidden_act, w_out), b_out, name='logits')\n",
    "            \n",
    "        return logits\n",
    "    \n",
    "    def __inference(self, logits):\n",
    "        with tf.name_scope('output_layer') as scope:\n",
    "            probs = tf.nn.softmax(logits, name='probabilities')\n",
    "            self.outputs = tf.argmax(probs, axis=0, name='prediction')\n",
    "\n",
    "    def __training(self, logits):\n",
    "        with tf.name_scope('labels') as scope:\n",
    "            self.Y_hat = tf.placeholder(tf.int32, [None, self.num_outputs], name='label')\n",
    "        with tf.name_scope('loss') as scope:\n",
    "            cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=self.Y_hat, name='cross_entropy')\n",
    "            self.loss = tf.reduce_mean(cross_entropy, name='loss')\n",
    "            self.loss_summary = tf.summary.scalar('loss_log', self.loss)\n",
    "        with tf.name_scope('optimizer') as scope:\n",
    "            self.lr = tf.placeholder(tf.float32, name='learning_rate')\n",
    "            self.mom = tf.placeholder(tf.float32, name='momentum')\n",
    "            self.optimizer = tf.train.MomentumOptimizer(self.lr, self.mom).minimize(self.loss)\n",
    "            \n",
    "    def __testing(self):\n",
    "        with tf.name_scope('testing_ops') as scope:\n",
    "            correct_preds = tf.equal(self.outputs, tf.argmax(self.Y_hat, axis=0))\n",
    "            self.num_correct = tf.reduce_sum(tf.cast(correct_preds, tf.float32))\n",
    "            \n",
    "    def train(self):\n",
    "        # load data\n",
    "        train, valid, test = self.__load_data()\n",
    "        with tf.Session() as sess:\n",
    "            # initialize variables\n",
    "            init_op = tf.global_variables_initializer()\n",
    "            sess.run(init_op)\n",
    "            with tf.summary.FileWriter(self.logdir, sess.graph) as writer:\n",
    "                writer.add_graph(sess.graph)\n",
    "                for i_epoch in range(self.num_epochs):\n",
    "                    # TRAINING PHASE\n",
    "                    print('Epoch: {:2d} - Training'.format(i_epoch+1))\n",
    "                    for i in range(len(train)):\n",
    "                        _, loss = sess.run([self.optimizer, self.loss_summary], feed_dict={self.X: train[i][0][None, :],\n",
    "                                                                                           self.Y_hat: train[i][1][None, :],\n",
    "                                                                                           self.lr: self.learning_rate,\n",
    "                                                                                           self.mom: self.momentum})\n",
    "                        writer.add_summary(loss, i_epoch*len(train)+i)\n",
    "                    # VALIDATION PHASE\n",
    "                    total_correct = 0.0\n",
    "                    for sample in valid:\n",
    "                        correct = sess.run(self.num_correct, feed_dict={self.X: sample[0][None, :],\n",
    "                                                                        self.Y_hat: sample[1][None, :]})\n",
    "                        total_correct += correct\n",
    "                    print('Epoch: {:2d} - Validation accuracy: {:6.2f}'.format(i_epoch+1, total_correct/len(valid)))\n",
    "                # TEST PHASE\n",
    "                total_correct = 0.0\n",
    "                for sample in test:\n",
    "                    correct = sess.run(self.num_correct, feed_dict={self.X: sample[0][None, :],\n",
    "                                                                    self.Y_hat: sample[1][None, :]})\n",
    "                    total_correct += correct\n",
    "                print('Test accuracy: {:6.2f}'.format(total_correct/len(test)))\n",
    "                # save model\n",
    "                self.saver.save(sess, os.path.join(self.logdir, 'fully_connected'))\n",
    "        \n",
    "    def infer(self, img):\n",
    "        #if tf.train.latest_checkpoint(self.logdir) is not None\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-e4616e77eb7b>:62: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "Extracting .\\MNIST\\data\\train-images-idx3-ubyte.gz\n",
      "Extracting .\\MNIST\\data\\train-labels-idx1-ubyte.gz\n",
      "Extracting .\\MNIST\\data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting .\\MNIST\\data\\t10k-labels-idx1-ubyte.gz\n",
      "Epoch:  1 - Training\n",
      "Epoch:  1 - Validation accuracy:  10.00\n",
      "Test accuracy:  10.00\n"
     ]
    }
   ],
   "source": [
    "mnist_fc = MNISTFullyConnected(100)\n",
    "mnist_fc.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=overfitregularize></a>\n",
    "### Overfitting and regularization\n",
    "\n",
    "#### Batch processing\n",
    "\n",
    "<img src='figures/batch_forward.png', width=360, height=360></img>\n",
    "<img src='figures/batch_backward.png', width=360, height=360></img>\n",
    "<img src='figures/delta_x_batch.png', width=640, height=640></img>\n",
    "<img src='figures/delta_w_batch.png', width=640, height=640></img>\n",
    "\n",
    "#### Dropout\n",
    "\n",
    "<img src='figures/dropout.png', width=360, height=360></img>\n",
    "\n",
    "#### Batch normalization\n",
    "\n",
    "<img src='figures/batch_normalization.png', width=480, height=480></img>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=sparseconnect></a>\n",
    "### Spatial locality and sparse connectivity\n",
    "\n",
    "The fundamental mathematical concept to understand CNNs is that of **test function**.\n",
    "Formally, a test function is a map\n",
    "\n",
    "$$\\Psi: \\mathbb{R}^n \\to \\mathbb{R}$$\n",
    "\n",
    "which is **smooth**, i.e. $\\Psi \\in \\mathcal{C}^{\\infty}(\\mathbb{R}^n)$, and **compactly supported**, i.e. the set $\\mathcal{S}_{\\Psi} = \\{x \\in \\mathbb{R}^n | \\Psi(x) \\neq 0\\}$ is a compact subset of $\\mathbb{R}^n$.\n",
    "\n",
    "The key property which regards CNNs is the second, the compact support property.\n",
    "An important result of real analysis states that a subset $\\mathcal{S}_{\\Psi} \\subset \\mathbb{R}^n$ is compact if and only if it is bounded: there exists a ball of radius $\\rho \\in \\mathbb{R}^{+}$ such that $\\mathcal{S}_{\\Psi}$ is contained in such a ball, i.e. $\\|x\\| \\leq \\rho, \\forall x \\in \\mathcal{S}_{\\Psi}$.\n",
    "\n",
    "To keep things simple, imagine to close your eyes and run a hand of yours on a coarse surface.\n",
    "Clearly, if the surface is sufficiently wide you just can't feel it all under your hand (i.e. your hand is a compactly supported function) and at any fixed time step and position you receive zero information about the coarsness of the part of surface that's outside your hand; but you are *testing* the part of surface that's beneath your hand and getting **local information** about the surface!\n",
    "Hence the name of test functions.\n",
    "\n",
    "The capital importance of test functions is their regularizing property.\n",
    "In fact, just like the hand of yours of the comparison, test functions can be slided all along the tested spaces and reveal bumps, cavities, or also *averagely flat* zones: this information is extracted by multiplying the test function with the underlying region in **convolution** or **cross-correlation** operations.\n",
    "Let $h(x)$ be a function measuring a quantity, and let $\\Psi(t)$ be a test function.\n",
    "A useful feature map $\\xi(h(x))$ which extracts information from $h$ can be obtained using a convolution:\n",
    "\n",
    "$$\\begin{align} \\xi(h(x)) &= \\Psi(t) * h(x) \\\\ &= \\int_{\\mathbb{R}^n} \\Psi(t) h(x-t) dt \\end{align}$$\n",
    "\n",
    "while another feature $\\phi(h(x))$ can be obtained using the slightly different cross-correlation:\n",
    "\n",
    "$$\\begin{align} \\phi(h(x)) &= \\Psi(t) * h(x) \\\\ &= \\int_{\\mathbb{R}^n} \\Psi(t) h(x+t) dt \\end{align}$$\n",
    "\n",
    "In CNNs jargon, the operation performed by every feature map in every convolutional layer is actually a cross-correlation, although it is improperly named *convolution*.\n",
    "\n",
    "<img src='figures/test_functions.png', width=480, height=480></img>\n",
    "<img src='figures/test_functions_discrete.png', width=480, height=480></img>\n",
    "<img src='figures/valid_padding.png', width=480, height=480></img>\n",
    "<img src='figures/same_padding.png', width=480, height=480></img>\n",
    "<img src='figures/sparse_connectivity.png', width=480, height=480></img>\n",
    "<img src='figures/vectorized_convolutions.png', width=480, height=480></img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=layers></a>\n",
    "### Layers\n",
    "\n",
    "TensorFlow provides a higher level, important abstraction over operations and variables.\n",
    "\n",
    "As the name says, a **layer** is an entity that is to be laid upon something else: it collects all the `Variable`s and `Operation`s needed to perform a desired high level mathematical transformation *upon* a previous feature $x$.\n",
    "For instance, it can implement a linear transformation followed by sigmoid activation\n",
    "\n",
    "$$\\phi(x) = \\sigma(xW + b)$$\n",
    "\n",
    "with a simple command\n",
    "\n",
    "```\n",
    "tf.layers.dense(x, num_units, activation=tf.nn.sigmoid, kernel_initializer=tf.truncated_normal_initializer())\n",
    "```\n",
    "\n",
    "where we suppose `x` to be an input tensor/operation.\n",
    "\n",
    "<img src='figures/dataflow_implementation_Layer.png', width=480, height=480></img>\n",
    "\n",
    "In the *dataflow* paradigm visualization we can think to layers as wrappers of simpler operations, as shown by the figure above: the first yellow layer implements an affine transformation (without activation) $s = xW + b$, the red layer implements a sigmoid activation of the score $h = \\sigma(s)$ while the last yellow layer performs a linear transformation $y = hW$ (no bias addition).\n",
    "\n",
    "The high-level view enabled by `layers` objects enormously increases modelling capabilities of researchers: it sacrifices computational efficiency (which better fits deployment requirements) for mathematical expressiveness.\n",
    "\n",
    "To end this introductory course on the mathematics and algorithms of Deep Learning we will thus implement a Convolutional Neural Network using `layers` to solve the MNIST multinomial regression task.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MNISTConvolutional():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __build(self):\n",
    "        pass\n",
    "    \n",
    "    def __load_data(self):\n",
    "        pass\n",
    "        \n",
    "    def train(self):\n",
    "        pass\n",
    "        \n",
    "    def infer(self):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_cnn = MNISTConvolutional()\n",
    "mnist_cnn.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "**TensorFlow**: [Stanford's course](http://web.stanford.edu/class/cs20si/) on *TensorFlow for Deep Learning research* is accurate, complete and comes along with a nice [GitHub repository](https://github.com/chiphuyen/stanford-tensorflow-tutorials).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
